"""
Editor Agent - krytycznie ocenia artykuÅ‚y i podejmuje decyzje redakcyjne.
UÅ¼ywa promptÃ³w z config/prompts.yaml.
UwzglÄ™dnia Clickbait Score z moduÅ‚u ML.
"""

import asyncio
import json

from src.llm_client import get_completion
from src.schemas import ArticleDraft, ReviewFeedback, ReviewDecision
from src.core.prompt_loader import get_agent_config


async def editor_agent(
    draft: ArticleDraft, 
    clickbait_score: float = 0.0
) -> ReviewFeedback:
    """
    Agent Editor - ocenia artykuÅ‚ i podejmuje decyzjÄ™ redakcyjnÄ….
    
    Args:
        draft: Szkic artykuÅ‚u od Writer Agent
        clickbait_score: Wynik z moduÅ‚u ML (0.0 = OK, 1.0 = clickbait)
        
    Returns:
        ReviewFeedback: Ocena i decyzja (ACCEPT/REVISE/REJECT)
    """
    # 1. Åadujemy konfiguracjÄ™ z YAML
    config = get_agent_config("editor")
    system_prompt = config["system_prompt"]
    
    # 2. WypeÅ‚niamy szablon prompta
    user_prompt = config["user_prompt_template"].format(
        title=draft.title,
        lead=draft.lead,
        body=draft.body,
        tags=", ".join(draft.tags),
        word_count=draft.word_count,
        clickbait_score=f"{clickbait_score:.2f}"
    )
    
    # 3. WysyÅ‚amy prompt do GPT-4
    response = await get_completion(user_prompt, system_prompt)
    
    # 4. Parsujemy JSON
    clean_response = response.strip()
    if clean_response.startswith("```"):
        clean_response = clean_response.split("```")[1]
        if clean_response.startswith("json"):
            clean_response = clean_response[4:]
    
    data = json.loads(clean_response)
    
    # 5. Mapowanie decision string na enum
    decision_map = {
        "approve": ReviewDecision.APPROVE,
        "revise": ReviewDecision.REVISE,
        "reject": ReviewDecision.REJECT,
    }
    data["decision"] = decision_map.get(data["decision"].lower(), ReviewDecision.REVISE)
    
    # 6. Walidacja przez Pydantic
    return ReviewFeedback(**data)


# --- Test peÅ‚nego pipeline ---
if __name__ == "__main__":
    from src.agents.research_agent import research_agent
    from src.agents.writer_agent import writer_agent
    
    # Symulacja moduÅ‚u ML (w przyszÅ‚oÅ›ci zastÄ…piony prawdziwym modelem)
    def mock_clickbait_detector(title: str) -> float:
        """
        Tymczasowy detektor clickbaitu.
        W przyszÅ‚oÅ›ci: model ML od InÅ¼yniera 1.
        """
        clickbait_words = [
            "szok", "nie uwierzysz", "tego nie wiedziaÅ‚eÅ›",
            "sekret", "zdradza", "!", "?"
        ]
        title_lower = title.lower()
        score = sum(1 for word in clickbait_words if word in title_lower)
        return min(score * 0.25, 1.0)  # Max 1.0
    
    async def main():
        print("ğŸ”„ PEÅNY PIPELINE: Research â†’ Writer â†’ Editor")
        print("=" * 60)
        
        # === KROK 1: RESEARCH ===
        print("\nğŸ” [1/3] Research Agent...")
        notes = await research_agent("przyszÅ‚oÅ›Ä‡ pracy zdalnej w IT")
        print(f"   âœ… Å¹rÃ³dÅ‚a: {len(notes.sources)}, Fakty: {len(notes.key_facts)}")
        
        # === KROK 2: WRITER ===
        print("\nâœï¸ [2/3] Writer Agent...")
        draft = await writer_agent(notes)
        print(f"   âœ… ArtykuÅ‚: '{draft.title}' ({draft.word_count} sÅ‚Ã³w)")
        
        # === KROK 3: ML CLICKBAIT DETECTION ===
        clickbait_score = mock_clickbait_detector(draft.title)
        print(f"\nğŸ¤– [ML] Clickbait Score: {clickbait_score:.2f}")
        
        # === KROK 4: EDITOR ===
        print("\nğŸ“‹ [3/3] Editor Agent...")
        review = await editor_agent(draft, clickbait_score)
        
        # === WYNIK ===
        print(f"\n{'=' * 60}")
        print(f"ğŸ“Š DECYZJA REDAKCYJNA")
        print(f"{'=' * 60}")
        
        decision_emoji = {
            ReviewDecision.APPROVE: "âœ… ACCEPT",
            ReviewDecision.REVISE: "ğŸ”„ REVISE",
            ReviewDecision.REJECT: "âŒ REJECT",
        }
        
        print(f"\n{decision_emoji[review.decision]} (Ocena: {review.overall_score}/10)")
        
        print(f"\nğŸ’ª Mocne strony:")
        for s in review.strengths:
            print(f"   â€¢ {s}")
        
        print(f"\nâš ï¸ Do poprawy:")
        for w in review.weaknesses:
            print(f"   â€¢ {w}")
        
        print(f"\nğŸ’¡ Sugestie:")
        for s in review.specific_suggestions:
            print(f"   â€¢ {s}")
        
        if review.fact_check_notes:
            print(f"\nğŸ” Fact-check: {review.fact_check_notes}")

    asyncio.run(main())

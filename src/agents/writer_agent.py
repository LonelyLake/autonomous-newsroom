"""
Writer Agent (Tech Journalist) - przekszta≈Çca ResearchNotes w artyku≈Ç Markdown.
U≈ºywa prompt√≥w z config/prompts.yaml.
Obs≈Çuguje feedback od Editora przy rewizjach.
"""

import asyncio
import json

from src.llm_client import get_completion
from src.schemas import ResearchNotes, ArticleDraft, ReviewFeedback
from src.core.prompt_loader import get_agent_config


async def writer_agent(
    research: ResearchNotes,
    feedback: ReviewFeedback | None = None
) -> ArticleDraft:
    """
    Agent Writer - pisze artyku≈Ç na podstawie notatek badawczych.
    
    Args:
        research: Notatki z agenta Research
        feedback: Opcjonalny feedback od Editora (przy rewizji)
        
    Returns:
        ArticleDraft: Szkic artyku≈Çu w formacie Markdown
    """
    # 1. ≈Åadujemy konfiguracjƒô z YAML
    config = get_agent_config("writer")
    system_prompt = config["system_prompt"]
    
    # 2. Formatujemy ≈∫r√≥d≈Ça do czytelnej formy
    sources_text = "\n".join([
        f"- {src.title} ({src.url or 'brak URL'}) - {src.summary}"
        for src in research.sources
    ])
    
    key_facts_text = "\n".join([f"- {fact}" for fact in research.key_facts])
    
    # 3. Wype≈Çniamy szablon prompta
    user_prompt = config["user_prompt_template"].format(
        topic=research.topic,
        sources=sources_text,
        key_facts=key_facts_text,
        suggested_angle=research.suggested_angle
    )
    
    # 4. Je≈õli jest feedback od Editora, dodaj go do prompta
    if feedback:
        feedback_section = f"""

=== FEEDBACK OD REDAKTORA (UWZGLƒòDNIJ KONIECZNIE!) ===
Poprzednia ocena: {feedback.overall_score}/10
Decyzja: {feedback.decision.value.upper()}

S≈ÅABE STRONY DO POPRAWY:
{chr(10).join(f'- {w}' for w in feedback.weaknesses)}

KONKRETNE SUGESTIE:
{chr(10).join(f'- {s}' for s in feedback.specific_suggestions)}

{f'UWAGI DO FAKT√ìW: {feedback.fact_check_notes}' if feedback.fact_check_notes else ''}

WA≈ªNE: Napisz NOWƒÑ, ULEPSZONƒÑ wersjƒô artyku≈Çu uwzglƒôdniajƒÖc powy≈ºsze uwagi!
"""
        user_prompt += feedback_section
    
    # 5. Wysy≈Çamy prompt do GPT-4
    response = await get_completion(user_prompt, system_prompt)
    
    # 6. Parsujemy JSON
    clean_response = response.strip()
    if clean_response.startswith("```"):
        clean_response = clean_response.split("```")[1]
        if clean_response.startswith("json"):
            clean_response = clean_response[4:]
    
    data = json.loads(clean_response)
    
    # 7. Ustaw wersjƒô draftu
    if feedback:
        # Je≈õli to rewizja, zwiƒôksz numer wersji
        data["version"] = getattr(feedback, "_iteration", 1) + 1
    
    # 8. Walidacja przez Pydantic
    return ArticleDraft(**data)


# --- Test agenta ---
if __name__ == "__main__":
    from src.agents.research_agent import research_agent
    
    async def main():
        print("üìù Pipeline: Research ‚Üí Writer")
        print("=" * 50)
        
        # Krok 1: Research
        print("\nüîç [1/2] Uruchamiam Research Agent...")
        notes = await research_agent("wp≈Çyw AI na rynek pracy w Polsce 2025")
        print(f"   ‚úÖ Zebrano {len(notes.sources)} ≈∫r√≥de≈Ç, {len(notes.key_facts)} fakt√≥w")
        
        # Krok 2: Writer
        print("\n‚úçÔ∏è [2/2] Uruchamiam Writer Agent...")
        draft = await writer_agent(notes)
        
        print(f"\n{'=' * 50}")
        print(f"üì∞ ARTYKU≈Å GOTOWY")
        print(f"{'=' * 50}")
        print(f"\n# {draft.title}\n")
        print(f"**Lead:** {draft.lead}\n")
        print(f"**Tre≈õƒá:**\n{draft.body[:500]}...")
        print(f"\n**Tagi:** {', '.join(draft.tags)}")
        print(f"**S≈Ç√≥w:** {draft.word_count}")

    asyncio.run(main())
